model:
  input_path: "./checkpoints/dslnet_wlasl_100_best_pruned.pth"
  output_path: "./checkpoints/dslnet_wlasl_100_best_qat.pth"
  num_classes: 100
  num_joints: 21
  embed_dim: 48  
quantization:
  backend: "qnnpack"    # qnnpack (ARM/mobile), fbgemm (x86)
  dtype: "qint8"       
  scheme: "per_channel" # per_channel || per_tensor
  mode: "dynamic"       

  qat:
    enabled: false      
    qconfig_name: "default"

  observer:
    type: "moving_average_min_max"  
    quant_min: -128
    quant_max: 127

data:
  root_dir: "./wlasl_data/videos"
  json_file: "./wlasl_data/wlasl100_converted/WLASL100_converted.json"
  calibration_samples: 500
  eval_samples: 1000

training:
  epochs: 10          
  batch_size: 16      
  learning_rate: 1e-5 
  weight_decay: 1e-4

input:
  num_frames: 32
  fill_missing_frames: true
  traj_normalize: true

optimizer:
  name: "adamw"
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  type: "cosine"
  warmup_epochs: 1

fusion:
  enabled: true
  layers:
    - ["conv", "bn", "relu"]  
    - ["conv", "bn"]         
    - ["linear", "relu"]     

evaluation:
  metrics: ["accuracy", "latency", "model_size"]
  top_k: [1, 5]
  compare_with_fp32: true  

benchmark:
  enabled: true
  batch_sizes: [1, 4, 8, 16, 32]
  num_runs: 100
  warmup_runs: 10

device: "cpu"  

save:
  output_path: "./checkpoints/dslnet_wlasl_100_best_qat.pth"
  save_quantized: true
  save_scripted: true
  save_onnx: false        

logging:
  log_dir: "./logs/qat"
  log_freq: 10
  plot_calibration: true  


compression:
  target_accuracy_drop: 0.02  
  min_compression_ratio: 2.0  

deployment:
  torchscript: true      
  onnx: false          
  tensorrt: false       
  coreml: false         

testing:
  enabled: true
  test_dataset: "val"  
  save_predictions: false 